import streamlit as st
import graphviz
import os
import google.generativeai as genai

# ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ­ã‚¸ãƒƒã‚¯ãƒ»é‹ç”¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from data import TOPOLOGY
from logic import CausalInferenceEngine, Alarm, simulate_cascade_failure
from network_ops import run_diagnostic_simulation

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="Antigravity Live", page_icon="âš¡", layout="wide")

# --- é–¢æ•°: ãƒˆãƒãƒ­ã‚¸ãƒ¼å›³ã®ç”Ÿæˆ ---
def render_topology(alarms, root_cause_node):
    graph = graphviz.Digraph()
    graph.attr(rankdir='TB')
    graph.attr('node', shape='box', style='rounded,filled', fontname='Helvetica')
    
    alarmed_ids = {a.device_id for a in alarms}
    
    for node_id, node in TOPOLOGY.items():
        color = "#e8f5e9" # Default Green
        penwidth = "1"
        fontcolor = "black"
        label = f"{node_id}\n({node.type})"
        
        if root_cause_node and node_id == root_cause_node.id:
            color = "#ffcdd2" # Root Cause Red
            penwidth = "3"
            label += "\n[ROOT CAUSE]"
        elif node_id in alarmed_ids:
            color = "#fff9c4" # Alarm Yellow
        
        graph.node(node_id, label=label, fillcolor=color, color='black', penwidth=penwidth, fontcolor=fontcolor)
    
    for node_id, node in TOPOLOGY.items():
        if node.parent_id:
            graph.edge(node.parent_id, node_id)
            parent_node = TOPOLOGY.get(node.parent_id)
            if parent_node and parent_node.redundancy_group:
                partners = [n.id for n in TOPOLOGY.values() 
                           if n.redundancy_group == parent_node.redundancy_group and n.id != parent_node.id]
                for partner_id in partners:
                    graph.edge(partner_id, node_id)
    return graph

# --- é–¢æ•°: Configè‡ªå‹•èª­ã¿è¾¼ã¿ ---
def load_config_by_id(device_id):
    path = f"configs/{device_id}.txt"
    if os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                return f.read()
        except Exception:
            return None
    return None

# --- UIæ§‹ç¯‰ ---
st.title("âš¡ Antigravity AI Agent (Live Demo)")

# APIã‚­ãƒ¼å–å¾—
api_key = None
if "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
else:
    api_key = os.environ.get("GOOGLE_API_KEY")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("âš¡ é‹ç”¨ãƒ¢ãƒ¼ãƒ‰é¸æŠ")
    selected_scenario = st.radio(
        "ã‚·ãƒŠãƒªã‚ª:", 
        ("æ­£å¸¸ç¨¼åƒ", "1. WANå…¨å›ç·šæ–­", "2. FWç‰‡ç³»éšœå®³", "3. L2SWã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³", "4. [Live] Ciscoå®Ÿæ©Ÿè¨ºæ–­")
    )
    
    st.markdown("---")
    if api_key:
        st.success("API Connected")
    else:
        st.warning("API Key Missing")
        user_key = st.text_input("Google API Key", type="password")
        if user_key: api_key = user_key

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ç®¡ç†
if "current_scenario" not in st.session_state:
    st.session_state.current_scenario = "æ­£å¸¸ç¨¼åƒ"
    st.session_state.messages = []
    st.session_state.chat_session = None 
    st.session_state.live_result = None
    st.session_state.trigger_analysis = False # è¨ºæ–­å¾Œã®åˆ†æãƒˆãƒªã‚¬ãƒ¼

# ã‚·ãƒŠãƒªã‚ªå¤‰æ›´æ™‚ã®ãƒªã‚»ãƒƒãƒˆå‡¦ç†
if st.session_state.current_scenario != selected_scenario:
    st.session_state.current_scenario = selected_scenario
    st.session_state.messages = []
    st.session_state.chat_session = None
    st.session_state.live_result = None
    st.session_state.trigger_analysis = False
    st.rerun()

# --- ã‚¢ãƒ©ãƒ¼ãƒ ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ ---
alarms = []
if selected_scenario == "1. WANå…¨å›ç·šæ–­":
    alarms = simulate_cascade_failure("WAN_ROUTER_01", TOPOLOGY)
elif selected_scenario == "2. FWç‰‡ç³»éšœå®³":
    alarms = [Alarm("FW_01_PRIMARY", "Heartbeat Loss", "WARNING")]
elif selected_scenario == "3. L2SWã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³":
    alarms = [Alarm("AP_01", "Connection Lost", "CRITICAL"), Alarm("AP_02", "Connection Lost", "CRITICAL")]

# æ¨è«–å®Ÿè¡Œ
root_cause = None
inference_result = None
reason = ""

if alarms:
    engine = CausalInferenceEngine(TOPOLOGY)
    inference_result = engine.analyze_alarms(alarms)
    root_cause = inference_result.root_cause_node
    reason = inference_result.root_cause_reason

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ ---
col1, col2 = st.columns([1, 1])

# å·¦ã‚«ãƒ©ãƒ ï¼šãƒˆãƒãƒ­ã‚¸ãƒ¼ ï¼† è‡ªå¾‹èª¿æŸ»UI
with col1:
    st.subheader("Network Status")
    st.graphviz_chart(render_topology(alarms, root_cause), use_container_width=True)
    
    if root_cause:
        st.markdown(
            f'<div style="color: #d32f2f; font-weight: bold; font-size: 15px; background-color: #fdecea; padding: 10px; border-radius: 5px;">'
            f'ğŸš¨ ç·Šæ€¥ã‚¢ãƒ©ãƒ¼ãƒˆï¼š{root_cause.id} ãƒ€ã‚¦ãƒ³'
            f'</div>', 
            unsafe_allow_html=True
        )
        st.caption(f"ç†ç”±: {reason}")
    
    is_live_mode = (selected_scenario == "4. [Live] Ciscoå®Ÿæ©Ÿè¨ºæ–­")
    
    if is_live_mode or root_cause:
        st.markdown("---")
        st.info("ğŸ›  **è‡ªå¾‹èª¿æŸ»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**")
        
        # ãƒœã‚¿ãƒ³: è¨ºæ–­å®Ÿè¡Œ
        if st.button("ğŸš€ è¨ºæ–­å®Ÿè¡Œ (Simulation)", type="primary"):
            if not api_key:
                st.error("API Key Required")
            else:
                with st.status("Agent Operating...", expanded=True) as status:
                    st.write("ğŸ”Œ Initiating connection simulation...")
                    res = run_diagnostic_simulation(selected_scenario)
                    st.session_state.live_result = res
                    
                    if res["status"] == "SUCCESS":
                        st.write("âœ… Data retrieved.")
                        status.update(label="Complete!", state="complete", expanded=False)
                    else:
                        st.write("âŒ Connection Failed (As expected).")
                        status.update(label="Target Unreachable", state="error", expanded=False)
                    
                    # ã€é‡è¦ä¿®æ­£ã€‘ãƒãƒ£ãƒƒãƒˆã‚’ãƒªã‚»ãƒƒãƒˆã›ãšã€æ¬¡ã®åˆ†æãƒˆãƒªã‚¬ãƒ¼ã ã‘ONã«ã™ã‚‹
                    st.session_state.trigger_analysis = True
                    st.rerun()

        # è¨ºæ–­çµæœè¡¨ç¤º
        if st.session_state.live_result:
            res = st.session_state.live_result
            if res["status"] == "SUCCESS":
                st.success("ğŸ›¡ï¸ **Data Sanitized**: ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ»IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ãƒã‚¹ã‚¯å‡¦ç†ã—ã¾ã—ãŸã€‚")
                with st.expander("ğŸ“„ å–å¾—ãƒ­ã‚° (Sanitized View)", expanded=True):
                    st.code(res["sanitized_log"], language="text")
            else:
                st.error(f"è¨ºæ–­çµæœ: {res['error']}")
                st.caption("â€»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã“ã®æ¥ç¶šã‚¨ãƒ©ãƒ¼è‡ªä½“ã‚’ã€è¨ºæ–­æƒ…å ±ã€ã¨ã—ã¦åˆ©ç”¨ã—ã¾ã™ã€‚")

# å³ã‚«ãƒ©ãƒ ï¼šAIãƒãƒ£ãƒƒãƒˆ
with col2:
    st.subheader("AI Analyst Report")

    if not api_key:
        st.error("APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        st.stop()

    # GeminiåˆæœŸè¨­å®š (ã¾ã ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒãªã„å ´åˆã®ã¿)
    if st.session_state.chat_session is None and selected_scenario != "æ­£å¸¸ç¨¼åƒ":
        genai.configure(api_key=api_key)
        generation_config = {"temperature": 0.0, "max_output_tokens": 1500}
        model = genai.GenerativeModel("gemini-2.0-flash", generation_config=generation_config)
        
        # --- åˆæœŸåˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (ãƒˆãƒãƒ­ã‚¸ãƒ¼è¦–ç‚¹) ---
        system_prompt = ""
        if root_cause:
            config_content = load_config_by_id(root_cause.id)
            system_prompt = f"""
            ã‚ãªãŸã¯AIOpsã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®éšœå®³ã«ã¤ã„ã¦åˆæœŸå ±å‘Šã—ã¦ãã ã•ã„ã€‚
            æ ¹æœ¬åŸå› : {root_cause.id} ({root_cause.type})
            ç†ç”±: {reason}
            """
            if config_content:
                system_prompt += f"\nã€Configã‚ã‚Šã€‘\n{config_content}\nä¸Šè¨˜è¨­å®šã«åŸºã¥ãã€ç–‘ã‚ã—ã„ç®‡æ‰€ã‚’æŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚"
            else:
                system_prompt += "\nã€Configãªã—ã€‘\nä¸€èˆ¬çš„ãªå¾©æ—§æ‰‹é †ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚"
            
            system_prompt += "\nãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: ç·Šæ€¥åº¦(çµµæ–‡å­—)ã€çŠ¶æ³è¦ç´„ã€æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³(èª¿æŸ»ãªã©)ã®é †ã€‚"

        if system_prompt:
            history = [{"role": "user", "parts": [system_prompt]}]
            chat = model.start_chat(history=history)
            try:
                with st.spinner("Initial Analysis..."):
                    response = chat.send_message("çŠ¶æ³å ±å‘Šã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚")
                    st.session_state.chat_session = chat
                    st.session_state.messages.append({"role": "assistant", "content": response.text})
            except Exception as e:
                st.error(f"Error: {e}")

    # --- è¨ºæ–­å®Ÿè¡Œå¾Œã®è¿½åŠ åˆ†æ (ãƒˆãƒªã‚¬ãƒ¼ãŒONã®æ™‚) ---
    if st.session_state.trigger_analysis and st.session_state.chat_session:
        live_data = st.session_state.live_result
        log_content = live_data.get('sanitized_log') or f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {live_data.get('error')}"
        
        # è¿½è¨˜ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        follow_up_prompt = f"""
        è‡ªå¾‹èª¿æŸ»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè¨ºæ–­ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã—ãŸã€‚
        ä»¥ä¸‹ã®å®Ÿè¡Œçµæœã«åŸºã¥ãã€è©³ç´°ãªã€ãƒã‚¯ã‚¹ãƒˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œãƒ¬ãƒãƒ¼ãƒˆã€ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

        ã€è¨ºæ–­å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã€‘
        ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {live_data['status']}
        è©³ç´°æƒ…å ±: {log_content}

        ã€å‡ºåŠ›è¦ä»¶ã€‘
        ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å‡ºåŠ›ã™ã‚‹ã“ã¨ã€‚
        
        ### ğŸ›  ãƒã‚¯ã‚¹ãƒˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œãƒ¬ãƒãƒ¼ãƒˆ
        
        **1. ãƒ‡ãƒ¼ã‚¿ä¿å…¨ã¨æ¥ç¶šç¢ºèª:**
        æ¥ç¶šè©¦è¡ŒãŠã‚ˆã³ãƒ­ã‚°å–å¾—ã‚’å®Ÿæ–½ã€‚
        â†’ **çµæœ: {live_data['status']}** (ğŸ›¡ï¸ æ©Ÿå¯†æƒ…å ±ã¯ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿)
        
        **2. è©³ç´°åˆ†æ:**
        [æ¥ç¶šã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ã€ç–é€šä¸å¯ã®ãŸã‚ç¢ºèªã§ãã¾ã›ã‚“ã€ã¨è¨˜è¿°ã€‚ãƒ­ã‚°ãŒã‚ã‚‹å ´åˆã¯å†…å®¹ã‚’åˆ†æ]
        â†’ [åˆ†æçµæœ]
        
        **3. ç‰©ç†/ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ç¢ºèª:**
        [æ¥ç¶šã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ã€é›»æºæ–­ã‚„ç‰©ç†éšœå®³ã®å¯èƒ½æ€§å¤§ã€ã¨æ¨è«–]
        â†’ [åˆ†æçµæœ]
        
        ---
        **æœ€çµ‚åˆ¤å®š:** [çµè«–]
        """
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦å±¥æ­´ã«è¿½åŠ 
        st.session_state.messages.append({"role": "user", "content": "è¨ºæ–­ã‚’å®Ÿè¡Œã—ã¾ã—ãŸã€‚çµæœã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚"})
        
        with st.spinner("Analyzing Diagnostic Data..."):
            try:
                response = st.session_state.chat_session.send_message(follow_up_prompt)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
            except Exception as e:
                st.error(f"Error: {e}")
        
        # ãƒˆãƒªã‚¬ãƒ¼ã‚’OFFã«æˆ»ã™
        st.session_state.trigger_analysis = False
        st.rerun()

    # --- ãƒãƒ£ãƒƒãƒˆUIè¡¨ç¤º (ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚³ãƒ³ãƒ†ãƒŠ) ---
    chat_container = st.container(height=600)
    
    with chat_container:
        for message in st.session_state.messages:
            # å†…éƒ¨çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯è¦‹ã›ãšã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¼šè©±ã¨ã—ã¦è‡ªç„¶ãªã‚‚ã®ã‚’è¡¨ç¤º
            if "ä»¥ä¸‹ã®è¨ºæ–­çµæœã«åŸºã¥ã" in message["content"]:
                continue # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè‡ªä½“ã¯éè¡¨ç¤ºã«ã™ã‚‹ãƒ•ã‚£ãƒ«ã‚¿
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    # å…¥åŠ›æ¬„
    if prompt := st.chat_input("AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«æŒ‡ç¤º..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with chat_container:
            with st.chat_message("user"):
                st.markdown(prompt)

        if st.session_state.chat_session:
            with chat_container:
                with st.chat_message("assistant"):
                    with st.spinner("Thinking..."):
                        try:
                            res = st.session_state.chat_session.send_message(prompt)
                            st.markdown(res.text)
                            st.session_state.messages.append({"role": "assistant", "content": res.text})
                        except Exception as e:
                            st.error(f"Error: {e}")
