import streamlit as st
import graphviz
import os
import google.generativeai as genai

from data import TOPOLOGY
from logic import CausalInferenceEngine, Alarm, simulate_cascade_failure
from network_ops import run_diagnostic_simulation

st.set_page_config(page_title="Antigravity Live", page_icon="âš¡", layout="wide")

# --- ãƒˆãƒãƒ­ã‚¸ãƒ¼æç”» ---
def render_topology(alarms, root_cause_node):
    graph = graphviz.Digraph()
    graph.attr(rankdir='TB')
    graph.attr('node', shape='box', style='rounded,filled', fontname='Helvetica')
    alarmed_ids = {a.device_id for a in alarms}
    for node_id, node in TOPOLOGY.items():
        color = "#e8f5e9"
        penwidth = "1"
        if root_cause_node and node_id == root_cause_node.id:
            color = "#ffcdd2"
            penwidth = "3"
        elif node_id in alarmed_ids:
            color = "#fff9c4"
        graph.node(node_id, label=f"{node_id}\n({node.type})", fillcolor=color, color='black', penwidth=penwidth)
    for node_id, node in TOPOLOGY.items():
        if node.parent_id:
            graph.edge(node.parent_id, node_id)
            parent = TOPOLOGY.get(node.parent_id)
            if parent and parent.redundancy_group:
                partners = [n.id for n in TOPOLOGY.values() if n.redundancy_group == parent.redundancy_group and n.id != parent.id]
                for p in partners: graph.edge(p, node_id)
    return graph

# --- Configèª­ã¿è¾¼ã¿ ---
def load_config_by_id(device_id):
    path = f"configs/{device_id}.txt"
    if os.path.exists(path):
        try: with open(path, "r", encoding="utf-8") as f: return f.read()
        except: return None
    return None

# --- UIæ§‹ç¯‰ ---
st.title("âš¡ Antigravity AI Agent (Live Demo)")

api_key = None
if "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
else:
    api_key = os.environ.get("GOOGLE_API_KEY")

with st.sidebar:
    st.header("âš¡ é‹ç”¨ãƒ¢ãƒ¼ãƒ‰é¸æŠ")
    selected_scenario = st.radio(
        "ã‚·ãƒŠãƒªã‚ª:", 
        ("æ­£å¸¸ç¨¼åƒ", "1. WANå…¨å›ç·šæ–­", "2. FWç‰‡ç³»éšœå®³", "3. L2SWã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³", "4. [Live] Ciscoå®Ÿæ©Ÿè¨ºæ–­")
    )
    if not api_key:
        st.warning("API Key Missing")
        user_key = st.text_input("Google API Key", type="password")
        if user_key: api_key = user_key

if "current_scenario" not in st.session_state:
    st.session_state.current_scenario = "æ­£å¸¸ç¨¼åƒ"
    st.session_state.messages = []
    st.session_state.chat_session = None 
    st.session_state.live_result = None
    st.session_state.trigger_analysis = False

if st.session_state.current_scenario != selected_scenario:
    st.session_state.current_scenario = selected_scenario
    st.session_state.messages = []
    st.session_state.chat_session = None
    st.session_state.live_result = None
    st.session_state.trigger_analysis = False
    st.rerun()

# --- ã‚¢ãƒ©ãƒ¼ãƒ ç”Ÿæˆ ---
alarms = []
if selected_scenario == "1. WANå…¨å›ç·šæ–­":
    alarms = simulate_cascade_failure("WAN_ROUTER_01", TOPOLOGY)
elif selected_scenario == "2. FWç‰‡ç³»éšœå®³":
    alarms = [Alarm("FW_01_PRIMARY", "Heartbeat Loss", "WARNING")]
elif selected_scenario == "3. L2SWã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³":
    alarms = [Alarm("AP_01", "Connection Lost", "CRITICAL"), Alarm("AP_02", "Connection Lost", "CRITICAL")]

root_cause = None
reason = ""
if alarms:
    engine = CausalInferenceEngine(TOPOLOGY)
    res = engine.analyze_alarms(alarms)
    root_cause = res.root_cause_node
    reason = res.root_cause_reason

# --- ç”»é¢ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ ---
col1, col2 = st.columns([1, 1])

# å·¦ã‚«ãƒ©ãƒ ï¼šãƒˆãƒãƒ­ã‚¸ãƒ¼ & è¨ºæ–­å®Ÿè¡Œ
with col1:
    st.subheader("Network Status")
    st.graphviz_chart(render_topology(alarms, root_cause), use_container_width=True)
    
    if root_cause:
        st.markdown(f'<div style="color:#d32f2f;background:#fdecea;padding:10px;border-radius:5px;">ğŸš¨ ç·Šæ€¥ã‚¢ãƒ©ãƒ¼ãƒˆï¼š{root_cause.id} ãƒ€ã‚¦ãƒ³</div>', unsafe_allow_html=True)
        st.caption(f"ç†ç”±: {reason}")
    
    is_live_mode = (selected_scenario == "4. [Live] Ciscoå®Ÿæ©Ÿè¨ºæ–­")
    
    if is_live_mode or root_cause:
        st.markdown("---")
        st.info("ğŸ›  **è‡ªå¾‹èª¿æŸ»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**")
        
        if st.button("ğŸš€ è¨ºæ–­å®Ÿè¡Œ (Auto-Diagnostic)", type="primary"):
            if not api_key:
                st.error("API Key Required")
            else:
                with st.status("Agent Operating...", expanded=True) as status:
                    st.write("ğŸ”Œ Establishing Connection...")
                    res = run_diagnostic_simulation(selected_scenario)
                    st.session_state.live_result = res
                    
                    if res["status"] == "SUCCESS":
                        st.write("âœ… Data Acquired.")
                        st.write("ğŸ§¹ Sanitizing Sensitive Information...")
                        status.update(label="Complete!", state="complete", expanded=False)
                    else:
                        st.write("âŒ Connection Failed.")
                        status.update(label="Target Unreachable", state="error", expanded=False)
                    
                    st.session_state.trigger_analysis = True
                    st.rerun()

        # è¨ºæ–­çµæœè¡¨ç¤ºï¼ˆã‚¿ãƒ–å½¢å¼ã«å¤‰æ›´ï¼‰
        if st.session_state.live_result:
            res = st.session_state.live_result
            if res["status"] == "SUCCESS":
                st.success("ğŸ›¡ï¸ **Data Sanitized**: æ©Ÿå¯†æƒ…å ±ã¯ãƒã‚¹ã‚¯å‡¦ç†æ¸ˆã¿")
                
                # ã‚¿ãƒ–ã§ç”Ÿãƒ­ã‚°ï¼ˆã‚µãƒ‹ã‚¿ã‚¤ã‚ºæ¸ˆï¼‰ã‚’è¦‹ã‚„ã™ãè¡¨ç¤º
                tab_log, tab_raw = st.tabs(["ğŸ”’ Sanitized Log", "ğŸ” Raw (Debug)"])
                with tab_log:
                    st.code(res["sanitized_log"], language="text")
                with tab_raw:
                    st.warning("ç®¡ç†æ¨©é™ãŒå¿…è¦ã§ã™")
            else:
                st.error(f"è¨ºæ–­çµæœ: {res['error']}")

# å³ã‚«ãƒ©ãƒ ï¼šAIãƒãƒ£ãƒƒãƒˆ
with col2:
    st.subheader("AI Analyst Report")
    if not api_key: st.stop()

    # åˆæœŸåŒ–
    should_start_chat = (st.session_state.chat_session is None) and (selected_scenario != "æ­£å¸¸ç¨¼åƒ")
    if should_start_chat:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel("gemini-2.0-flash", generation_config={"temperature": 0.0})
        
        system_prompt = ""
        if st.session_state.live_result:
            # Liveãƒ¢ãƒ¼ãƒ‰ã®åˆæœŸåŒ–ï¼ˆå†èµ·å‹•æ™‚ãªã©ï¼‰
            live_data = st.session_state.live_result
            log_content = live_data.get('sanitized_log') or f"Error: {live_data.get('error')}"
            system_prompt = f"è¨ºæ–­çµæœã«åŸºã¥ããƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã›ã‚ˆã€‚\nã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {live_data['status']}\nãƒ­ã‚°: {log_content}"
        elif root_cause:
            conf = load_config_by_id(root_cause.id)
            system_prompt = f"éšœå®³å ±å‘Š: {root_cause.id}ã€‚ç†ç”±: {reason}ã€‚"
            if conf: system_prompt += f"\nConfig:\n{conf}"
        
        if system_prompt:
            chat = model.start_chat(history=[{"role": "user", "parts": [system_prompt]}])
            try:
                with st.spinner("Analyzing..."):
                    res = chat.send_message("çŠ¶æ³å ±å‘Šã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚")
                    st.session_state.chat_session = chat
                    st.session_state.messages.append({"role": "assistant", "content": res.text})
            except Exception as e: st.error(str(e))

    # è¨ºæ–­å¾Œã®è¿½åŠ åˆ†æ (ãƒˆãƒªã‚¬ãƒ¼)
    if st.session_state.trigger_analysis and st.session_state.chat_session:
        live_data = st.session_state.live_result
        log_content = live_data.get('sanitized_log') or f"Error: {live_data.get('error')}"
        
        prompt = f"""
        è¨ºæ–­ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã—ãŸã€‚ä»¥ä¸‹ã®çµæœã«åŸºã¥ãã€ãƒã‚¯ã‚¹ãƒˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œãƒ¬ãƒãƒ¼ãƒˆã€ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
        
        ã€è¨ºæ–­ãƒ‡ãƒ¼ã‚¿ã€‘
        ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {live_data['status']}
        ãƒ­ã‚°: {log_content}
        
        ã€å‡ºåŠ›è¦ä»¶ã€‘
        1. æ¥ç¶šçµæœ (æˆåŠŸ/å¤±æ•—)
        2. ãƒ­ã‚°åˆ†æ (ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹çŠ¶æ…‹ã€ãƒ«ãƒ¼ãƒˆæƒ…å ±ãªã©)
        3. æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        """
        st.session_state.messages.append({"role": "user", "content": "è¨ºæ–­çµæœã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚"})
        
        with st.spinner("Analyzing Diagnostic Data..."):
            try:
                res = st.session_state.chat_session.send_message(prompt)
                st.session_state.messages.append({"role": "assistant", "content": res.text})
            except Exception as e: st.error(str(e))
        
        st.session_state.trigger_analysis = False
        st.rerun()

    # ãƒãƒ£ãƒƒãƒˆUI
    chat_container = st.container(height=600)
    with chat_container:
        for msg in st.session_state.messages:
            if "è¨ºæ–­çµæœã«åŸºã¥ã" in msg["content"]: continue
            with st.chat_message(msg["role"]): st.markdown(msg["content"])

    if prompt := st.chat_input("è³ªå•..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with chat_container:
            with st.chat_message("user"): st.markdown(prompt)
        if st.session_state.chat_session:
            with chat_container:
                with st.chat_message("assistant"):
                    with st.spinner("Thinking..."):
                        res = st.session_state.chat_session.send_message(prompt)
                        st.markdown(res.text)
                        st.session_state.messages.append({"role": "assistant", "content": res.text})
